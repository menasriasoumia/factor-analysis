{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNJt3NC3f8U5V5c+5ij9MEv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# -*- coding: UTF-8 -*-\n","import MySQLdb\n","import numpy as np\n","import random\n","from collections import Counter\n","import scipy\n","from pandas import *\n","from sklearn.ensemble import RandomForestClassifier\n","import time"],"metadata":{"id":"9cPrhznQW_a3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HfPO57EeVjmo"},"outputs":[],"source":["# ---------------------------------------------------------------------------------------------------------------------\n","SENSORDIRS = {'accelerometer': r\"HASC1001-acc.csv\"}\n","AXES = (('x', 3), ('y', 2), ('z', 1))\n","#the features we use\n","SINGLE_FEATURES = {\n","    'average-absolute-difference': 1,'standarddev': np.std, 'variance': np.var,\n","    'nanmin':np.nanmin, 'nanmax':np.nanmax, 'median':np.median, 'average':np.average,\n","    'percentile_70':2,'percentile_80':3,'percentile_90':4,\n","    'dominant-frequency': 5,'energy': 6\n","} #all features working on one axis\n","AXIS_TUPLE_NAME = 0\n","def generateHeader():\n","    header = []\n","\n","    for fKey, func in SINGLE_FEATURES.items():\n","        for axis in AXES:\n","            header.append(''.join([ axis[AXIS_TUPLE_NAME], '-', fKey]))\n","\n","    return header\n","def generateArff(data,actionlist):\n","    label=Series(actionlist)\n","    s = np.unique(label)#\"Uniq\" to remove duplicates in tags.\n","    mapping = Series([x[0] for x in enumerate(s)], index = s)\n","    label=label.map(mapping)\n","     #initialize random forests\n","    rf=RandomForestClassifier(n_estimators=100,criterion = \"entropy\")\n","    #run algorithm\n","    result=kfold(rf,np.array(data),label)#10-cross_validation\n","    return  result\n","\n","\n","# cross-validation\n","def kfold(clr,X,y,folds=10):\n","    from sklearn.cross_validation import KFold\n","    from sklearn import metrics\n","    auc_sum=0\n","    kf = KFold(y.shape[0],n_folds=10,shuffle = True)#K-Folds cross validation iterator\n","    for train_index, test_index in kf:\n","        X_train, X_test = X[train_index], X[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","        clr.fit(X_train, y_train)#Build a forest of trees from the training set\n","        pred_test = clr.predict(X_test)#Predict class for X\n","        print metrics.accuracy_score(y_test,pred_test)#Accuracy classification score\n","        auc_sum+=metrics.accuracy_score(y_test,pred_test)\n","        from sklearn.metrics import confusion_matrix\n","        print confusion_matrix(y_test,pred_test)\n","\n","    result = auc_sum/folds\n","    return result\n","\n","\n","def computeMI(x, y):\n","    sum_mi = 0.0\n","    #p(x)\n","    x=[round(float(i),1) for i in x]\n","    xcounts = Counter(x)\n","    x_value_list = []\n","    pxlist=[]\n","    for key,value in xcounts.items():\n","        x_value_list.append(key)\n","        px=float(value)/float(len(x))\n","        pxlist.append(px)\n","    #p(y)\n","    ycounts = Counter(y)\n","    y_value_list = []\n","    pylist=[]\n","    for key,value in ycounts.items():\n","        y_value_list.append(key)\n","        py=float(value)/float(len(y))\n","        pylist.append(py)\n","\n","    #p(x,y)\n","    for i,v in enumerate(y_value_list):\n","        py=pylist[i]\n","        for n,e in enumerate(x_value_list):\n","            px=pxlist[n]\n","            xycount=0\n","            # for num,element in enumerate(x):\n","            #     if element == e and y[num]==v:\n","            #         xycount+=1\n","            for num,element in enumerate(y):\n","                if element == v and x[num]==e:\n","                    xycount+=1\n","            if xycount>0:\n","                pxy=float(xycount)/float(len(y))\n","                t=pxy/(px*py)\n","                sum_mi+=pxy*np.log10(t)\n","    return sum_mi\n","\n","\n","def conn():\n","    # Open database connection.\n","    db = MySQLdb.connect('localhost','root','meng','AccelerationData' )\n","\n","    with db:\n","        #Still, the first step is to get the cursor object of the connection to execute the query.\n","        cur = db.cursor()\n","        sql1 = \"set interactive_timeout = 2880000\"\n","        cur.execute(sql1)\n","        sql2 = \"set wait_timeout=2880000\"\n","        cur.execute(sql2)\n","        #Similar to the query function in other languages, execute is the function used to execute a query in Python.\n","\n","\n","        #Query separately\n","        # args=['Person1201', 'Person1202']\n","        # rates=[100,75]\n","        # for i in range(len(args)):\n","        #     for j in range(len(rates)):\n","        #         sql = \"SELECT * FROM AccelerationData.featuredata WHERE PersonID ='\" + str(args[i]) + \"'AND SampleRate ='\" + str(rates[j])+\"'\"\n","        #         cur.execute(sql)\n","        #\n","\n","        args=()\n","        allperson=range(1201,1308)\n","        # choose=random.sample(allperson,10)\n","\n","        #10-1\n","        # choose=[1259, 1291, 1294, 1209, 1241, 1231, 1264, 1275, 1215, 1208]\n","        #10-2\n","        choose=[1293, 1246, 1208, 1254, 1215, 1225, 1264, 1219, 1291, 1233]\n","\n","\n","        #30-1\n","        # choose=[1205, 1241, 1297, 1223, 1296, 1214, 1304, 1277, 1207, 1246, 1221, 1239, 1266, 1238, 1249, 1281, 1228, 1262, 1218, 1211, 1299, 1244, 1279, 1206, 1301, 1307, 1291, 1254, 1233, 1253]\n","        #30-2\n","        # choose=[1224, 1244, 1249, 1225, 1296, 1247, 1291, 1234, 1229, 1201, 1271, 1203, 1283, 1246, 1304, 1267, 1264, 1277, 1254, 1281, 1301, 1288, 1270, 1279, 1285, 1262, 1295, 1222, 1221, 1306]\n","\n","        #50\n","        # choose=[1240, 1265, 1234, 1302, 1291, 1271, 1233, 1225, 1270, 1298, 1245, 1263, 1222, 1259, 1266, 1273, 1281, 1215, 1274, 1226, 1247, 1246, 1241, 1248, 1256, 1306, 1280, 1230, 1242, 1211, 1219, 1276, 1282, 1220, 1277, 1253, 1269, 1260, 1264, 1237, 1294, 1258, 1304, 1217, 1212, 1210, 1252, 1257, 1243, 1289]\n","\n","        #70\n","        # choose=[1275, 1227, 1271, 1272, 1273, 1225, 1201, 1248, 1282, 1253, 1251, 1301, 1212, 1210, 1286, 1229, 1295, 1243, 1269, 1224, 1203, 1226, 1279, 1290, 1257, 1287, 1207, 1244, 1232, 1297, 1270, 1254, 1302, 1208, 1217, 1298, 1215, 1261, 1299, 1214, 1206, 1236, 1256, 1220, 1284, 1277, 1202, 1250, 1274, 1205, 1307, 1259, 1209, 1304, 1289, 1288, 1291, 1255, 1239, 1264, 1242, 1300, 1241, 1222, 1278, 1293, 1296, 1238, 1268, 1230]\n","        #100\n","        #  choose=[1256, 1307, 1268, 1266, 1291, 1300, 1210, 1232, 1302, 1276, 1216, 1293, 1285, 1261, 1284, 1278, 1292, 1248, 1280, 1251, 1267, 1206, 1304, 1212, 1258, 1207, 1287, 1221, 1238, 1271, 1243, 1272, 1214, 1299, 1255, 1265, 1260, 1203, 1263, 1259, 1294, 1296, 1253, 1233, 1242, 1305, 1247, 1306, 1262, 1211, 1209, 1295, 1281, 1246, 1236, 1235, 1230, 1204, 1219, 1289, 1301, 1224, 1254, 1244, 1257, 1208, 1264, 1277, 1213, 1288, 1270, 1202, 1240, 1274, 1282, 1241, 1217, 1205, 1297, 1252, 1229, 1298, 1303, 1249, 1218, 1201, 1223, 1250, 1215, 1226, 1273, 1279, 1234, 1283, 1275, 1290, 1225, 1286, 1231, 1222]\n","        # sample_rate=5\n","        samplelist=[100,95,90,85,80,75,70,65,60,55,50,45,40,35,30,25,20,15,10,5,4]\n","        print choose\n","        for sample_rate in samplelist:\n","            for c in  choose:\n","                args = args+('Person'+str(c),)\n","            # args=('Person1201', 'Person1202')\n","            rates=(sample_rate)\n","            sql_command =\"SELECT * FROM AccelerationData.featuredata_new where PersonID IN \"+str(args)+ \"and SampleRate =\"+ str(rates)\n","            cur.execute(sql_command)\n","            #Use the fetchall function to store the result set (a multidimensional tuple) into the variable \"rows\".\n","            rows = cur.fetchall()\n","            data = np.asarray(rows)\n","            actionlist=data[:,2]\n","            data = scipy.delete(data, (0,1,2,3,4,5,6), 1)\n","            sql = \"set interactive_timeout=24*3600\"\n","            cur.execute(sql)\n","            result = generateArff(data,actionlist)\n","            sizes = len(data[0])\n","            # #Iterate through the result set one by one, and for each element found, which represents a record in the table, use a tuple to display it.\n","            output = [102,'Activity',sample_rate]\n","            sumMul=0.0\n","            for column in range(0,sizes):\n","                IXiY=computeMI(data[:,column],actionlist)\n","                sumMul+=IXiY\n","                output.append(IXiY)\n","            output.append(sumMul)\n","            print output\n","            output.append(result)\n","            stmt = \"INSERT INTO mutualinformation_new (PersonNum,RecognitionType,SampleRate,Xenergy,Yenergy,Zenergy,Xperseven,Yperseven,Zperseven,Xstandarddev,Ystandarddev,Zstandarddev,Xdomfre,Ydomfre,Zdomfre,Xaverageabsdif,Yaverageabsdif,Zaverageabsdif,Xaverage,Yaverage,Zaverage,Xmedian,Ymedian,Zmedian,Xpereight,Ypereight,Zpereight,Xpernine,Ypernine,Zpernine,Xnanmin,Ynanmin,Znanmin,Xvariance,Yvariance,Zvariance,Xnanmax,Ynanmax,Znanmax,Total,Accuracy) VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\n","            cur.execute(stmt, output)\n","        db.commit()\n","        # Close database connection.\n","        db.close()\n"]},{"cell_type":"code","source":["def main():\n","    conn()\n"],"metadata":{"id":"Y7PqkTzbVwmG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    begin = time.clock()\n","    main()\n","    end = time.clock()\n","    print end-begin"],"metadata":{"id":"L8yYlw72Vqz2"},"execution_count":null,"outputs":[]}]}