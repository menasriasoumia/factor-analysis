{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO6RElGxtk9Sfd+dIUyN94t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4fXLnD6FR-jF"},"outputs":[],"source":["# coding=utf8\n","\n","\n","from numpy import mean, absolute\n","import os\n","import MyQueue\n","import numpy as np\n","import scipy\n","import random\n","import fractions"]},{"cell_type":"code","source":["#write a file \n","def writecsv(addlabel,filename):\n","    with open(filename, 'a') as the_file:\n","        for i in addlabel:\n","            the_file.write(str(i)[1:-1].replace('\\'','')+'\\n')"],"metadata":{"id":"wGAXrVq5VYOe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set the time window to 1 second, read the csv files in the addlabel file.\n","# Each file within the same second is considered as a window. Remove the first and last two time windows, reduce the sampling rate within each window, and store the data with reduced sampling rate in the reduce file. \n","# this is for user observation. Extract features from the data within each window to generate an arff file.\n","def window_slide(filepath,sample_rate):\n","     featurelist=[]\n","     for root, dirs, files in os.walk(filepath):\n","        for fn in files:\n","            # if 'HASC22203' in fn:\n","                filename = root+'/'+fn\n","                # Read a CSV file.\n","                FileID= filename.split('/')[-1].split('.')[0]\n","                PersonID = filename.split('/')[-2][0:10]\n","                sampleRate=0\n","                if sample_rate!=25:\n","                    sampleRate=sample_rate*5\n","                else:\n","                    sampleRate=4\n","                with  open(filename, 'r') as f:\n","                    lines=f.readlines()\n","                    linelist = []\n","                    # Each file is placed in a time window based on the position of the decimal point before the time value. The time window is set to 2 seconds.\n","                    for line in lines:\n","                        time,x,y,z,label= line.strip().split(',')\n","                        if len(linelist)==0:\n","                            s = MyQueue.Queue()\n","                            t = (time,x,y,z,label,FileID,PersonID,sampleRate)\n","                            s.enqueue(t)\n","                            linelist.append(s)\n","\n","                        else:\n","                            s = linelist[-1]\n","                            pretime=s.peek()[0][0:10]\n","                            if time[0:10]==pretime :#or int(time[0:10])==int(pretime)+1 If the time is the same or the interval is one second, they are considered as belonging to the same window.\n","                                t = (time,x,y,z,label,FileID,PersonID,sampleRate)\n","                                s.enqueue(t)\n","                            else:\n","                                s = MyQueue.Queue()\n","                                t = (time,x,y,z,label,FileID,PersonID,sampleRate)\n","                                s.enqueue(t)\n","                                linelist.append(s)\n","\n","                    linelist.pop(0)\n","                    linelist.pop()\n","                #\n","                    reducelist=[]\n","                    for index,value in enumerate(linelist):\n","                        #  the sampling rate, with values of 1, 2, 4, 5, 10, 20, or 25. The original data is 200 Hz, meaning there are 200 samples per second. \n","                        #  If \"sample_rate\" is set to 2, then the sampling rate is reduced to half, resulting in 100 samples per second.\n","                        if sampleRate==4 :\n","                            w=value.elements[0:len(value.elements):sample_rate]\n","                            reducelist.append(w)\n","                        elif sampleRate==100 :\n","                                w=value.elements[0:len(value.elements):1]\n","                                reducelist.append(w)\n","                        else:\n","                            tmp=[]\n","                            for i in range(0,len(value.elements),20):\n","                                b=value.elements[i:i+20]\n","                                tmp+=b[0:sample_rate]\n","                            reducelist.append(tmp)\n","\n","                    # reduceoutput=[]\n","                    # for i in reducelist:\n","                    #     for j in  i:\n","                    #         reduceoutput.append((j[0],j[1],j[2],j[3]))\n","                    # writecsv(reduceoutput,'reduce5/'+fn)\n","\n","\n","                    count=0\n","                    for i,v in  enumerate(reducelist):\n","                        if len(v)>=4:\n","                            fs=getFeature(v)\n","                            count+=1\n","                            oneline = fs+(count,)\n","                            featurelist.append(oneline)\n","\n","\n","     return featurelist"],"metadata":{"id":"sAPhAbb2S1Al"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def meanad(data, axis=None):\n","    return mean(absolute(data - mean(data, axis)), axis)\n","\n","def percentile_70(axis):\n","    return  np.percentile(axis, 70)\n","\n","\n","def percentile_80(axis):\n","    return  np.percentile(axis, 80)\n","\n","\n","def percentile_90(axis):\n","    return  np.percentile(axis, 90)\n","\n","SAMPLES_PER_SECOND = 100\n","def peak_frequency(axis, SAMPLES_PER_SECOND):\n","    spacing=1.0 / SAMPLES_PER_SECOND\n","    spectrum = scipy.fft(axis)[:len(axis) / 2]\n","    freqs = np.fft.fftfreq(len(spectrum), d=spacing)[:len(axis) / 2]\n","    spectrum[0] = 0\n","    return freqs[np.argmax(np.abs(spectrum))]\n","\n","def energy(axis, spacing=1.0 / SAMPLES_PER_SECOND):\n","    spectrum = scipy.fft(axis)[:len(axis) / 2]\n","    return np.sqrt(np.sum(np.square(np.abs(spectrum))) / len(axis))"],"metadata":{"id":"DgoSRnjwSskF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def getFeature(windowlist):\n","    time=[]\n","    x=[]\n","    y=[]\n","    z=[]\n","    UnixTime=windowlist[0][0][0:10]\n","    label=windowlist[0][4]\n","    FileID=windowlist[0][5]\n","    PersonID=windowlist[0][6]\n","    sample_rate=windowlist[0][7]\n","    for element in windowlist :\n","        time.append(element[0])\n","        x.append(float(element[1]))\n","        y.append(float(element[2]))\n","        z.append(float(element[3]))\n","    # print x\n","    NUMBER_FORMAT = \"%.6f\"\n","    x=np.array(x)\n","    y=np.array(y)\n","    z=np.array(z)\n","    x70=NUMBER_FORMAT % percentile_70(x)\n","    y70=NUMBER_FORMAT % percentile_70(y)\n","    z70=NUMBER_FORMAT % percentile_70(z)\n","    x80=NUMBER_FORMAT % percentile_80(x)\n","    y80=NUMBER_FORMAT % percentile_80(y)\n","    z80=NUMBER_FORMAT % percentile_80(z)\n","    x90=NUMBER_FORMAT % percentile_90(x)\n","    y90=NUMBER_FORMAT % percentile_90(y)\n","    z90=NUMBER_FORMAT % percentile_90(z)\n","    px=NUMBER_FORMAT % peak_frequency(x,sample_rate)\n","    py=NUMBER_FORMAT % peak_frequency(y,sample_rate)\n","    pz=NUMBER_FORMAT % peak_frequency(z,sample_rate)\n","    energyx=NUMBER_FORMAT % energy(x)\n","    energyy=NUMBER_FORMAT % energy(y)\n","    energyz=NUMBER_FORMAT % energy(z)\n","    sx = NUMBER_FORMAT % np.std(x)\n","    sy = NUMBER_FORMAT % np.std(y)\n","    sz = NUMBER_FORMAT % np.std(z)\n","    averagex = NUMBER_FORMAT % np.average(x)\n","    averagey = NUMBER_FORMAT % np.average(y)\n","    averagez = NUMBER_FORMAT % np.average(z)\n","    medianx = NUMBER_FORMAT % np.median(x)\n","    mediany = NUMBER_FORMAT % np.median(y)\n","    medianz = NUMBER_FORMAT % np.median(z)\n","    minx = NUMBER_FORMAT % np.nanmin(x)\n","    miny = NUMBER_FORMAT % np.nanmin(y)\n","    minz = NUMBER_FORMAT % np.nanmin(z)\n","    varx = NUMBER_FORMAT % np.var(x)\n","    vary = NUMBER_FORMAT % np.var(y)\n","    varz = NUMBER_FORMAT % np.var(z)\n","    maxx = NUMBER_FORMAT % np.nanmax(x)\n","    maxy = NUMBER_FORMAT % np.nanmax(y)\n","    maxz = NUMBER_FORMAT % np.nanmax(z)\n","    madx = NUMBER_FORMAT % meanad(x)\n","    mady = NUMBER_FORMAT % meanad(y)\n","    madz = NUMBER_FORMAT % meanad(z)\n","    return PersonID,label,FileID,UnixTime,sample_rate,energyx,energyy,energyz,x70,y70,z70,sx,sy,sz,px,py,pz,madx,mady,madz,averagex,averagey,averagez,\\\n","           medianx,mediany,medianz,x80,y80,z80,x90,y90,z90,minx,miny,minz,\\\n","           varx,vary,varz,maxx,maxy,maxz"],"metadata":{"id":"msFAKoISSiEU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SENSORDIRS = {'accelerometer': r\"HASC1001-acc.csv\"}\n","AXES = (('x', 3), ('y', 2), ('z', 1))\n","#the features we use\n","SINGLE_FEATURES = {\n","    'average-absolute-difference': meanad,'standarddev': np.std, 'variance': np.var,\n","    'nanmin':np.nanmin, 'nanmax':np.nanmax, 'median':np.median, 'average':np.average,\n","    'percentile_70':percentile_70,'percentile_80':percentile_80,'percentile_90':percentile_90,\n","    'dominant-frequency': peak_frequency,'energy': energy\n","} #all features working on one axis\n"],"metadata":{"id":"FwLKY7TSSdJ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main():\n","    path='/personall_old'\n","\n","    num=[]\n","    for i in range(1,21):\n","        num.append(i)\n","    num.append(25)\n","    for i in num:\n","        chooselist= []\n","        for root, dirs, files in os.walk(path):\n","            if 'Person' in root:\n","                person=int(root[57:61])\n","                # person=int(root[60:64])\n","                features = window_slide(root,i)\n","                chooselist.append(features)\n","    #\n","        with open('/AllFeature3.csv', 'a') as the_file:\n","                for c in chooselist:\n","                    for i in  c:\n","                        if '@' not in i:\n","                            the_file.write(str(i)[1:-1].replace('\\'','')+'\\n')\n","                        else:\n","                            the_file.write(i+'\\n')"],"metadata":{"id":"uV-pXdxHSZCF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    main()"],"metadata":{"id":"qj_FqRLhSWjV"},"execution_count":null,"outputs":[]}]}